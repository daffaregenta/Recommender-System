#Source Code TUBES CLO 3 â€“ Sistem Pemberi Rekomendasi
#Untuk source code asli (google colab) dapat diakses melalui link berikut: https://colab.research.google.com/drive/1_rCjlao2fXn_cTPUJyJMa8pTqzKCaTvY?usp=sharing

# -*- coding: utf-8 -*-
"""TUBES CLO 3 - Sistem Pemberi Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_rCjlao2fXn_cTPUJyJMa8pTqzKCaTvY

# Deskripsi TUBES Sistem Pemberi Rekomendasi

Buatlah sebuah Aplikasi content based recommender system sederhana, boleh memanfaatkan dataset dare kaggle atau yang lain. Domain bebas.

1. Tugas bersifat kelompok, salah satu anggota kelompok saja yang submit ke LMS

2. Tuliskan peran dari masing-masing anggota kelompok dalam pengerjaan tugas ini

3. Buatlah video untuk menjelaskan aplikasi anda

4. Aplikasi harus ada GUI sederhana

5. Submit Tugas Kuliah dalam bentuk file zip atau rar, terdiri dari :

     - File pptx yang menjelaskan aplikasi anda dan metode yang digunakan, termasuk beberapa screen shot dari aplikasi. Tuliskan anggota kelompok dan link video youtube nya

     - File sourcecode dalam word

     - File dataset (jika memanfaatkan dataset)

6. Video berupa penjelasan dari file pptx anda, serta penjelasan program dan jalannya aplikasi, dan diupload di youtube. Durasi maksimal adalah 15 menit

7.  Penilaian kelopok berdasarkan kualitas aplikasi, penjelasan dalam video, dan metode yang digunakan.

8. Penilaian individu berdasarkan keaktifan mahasiswa bertanya dalam kolom komentar di setiap video kelompok lain, serta keaktifan menjawab pertanyaan. Kualitas pertanyaan juga dipertimbangkan dalam penilaian

9. Submission Tubes beserta uploading video di youtube adalah dalam selang waktu tanggal **27 - 31 Desember 2021**, dan masa diskusi tanya jawab dalam kolom komentar di youtube adalah tanggal **27 Des 2021 - 3 Jan 2021**.

# Milestones Pengerjaan TUBES

*   Pencarian Data Set yang akan Digunakan
*   Pembangunan Sistem Rekomendasi
*   Perancangan GUI Aplikasi
*   Pembuatan Presentasi PPT
*   Video Presentasi TUBES

# Intro

Dalam tugas besar Sistem Pemberi Rekomendasi ini, kami akan membuat aplikasi sistem pemberi rekomendasi *content-based* sederhana. Domain yang kami pilih adalah tentang film. Aplikasi yang akan dibangun akan merekomendasikan film berdasarkan 1000 film teratas dalam *Internet Movie Database* (IMDB).

# Import Library

Berikut adalah library-library yang akan digunakan selama pembangunan sistem aplikasi rekomendasi.
"""

# library umum yang akan digunakan
import pandas as pd
import sklearn as sk
import math 
import numpy as np

# library untuk mengabaikan warnings
import warnings
warnings.filterwarnings('ignore')

# library untuk mengambil stopwords dalam bahasa Inggris
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

# library untuk melakukan stemming pada data
from nltk.stem import PorterStemmer
stemmer = PorterStemmer()

# library TF-IDF dan cosine similarity
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

"""# Download Data Set

Dataset yang kami gunakan bersumber dari tautan [berikut](https://www.kaggle.com/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows).
"""

# download dataset dari google drive
!gdown --id 1Ruijucx_zDPwRhoLRMjwC5jmgqxXLoCy

# membaca dataset ke dalam bentuk data frame
df_mov = pd.read_csv('imdb_top_1000.csv')

"""# Data Exploration

Pada tahap ini akan menampilkan informasi dasar seputar dataset yang digunakan. Eksplorasi data mencakup penampilan sampel, ukuran, deskripsi, dan informasi tetang dataset.
"""

# menampilkan sampel data lima teratas
df_mov.head()

# menampilkan ukuran baris dan kolom dari dataset
print("Terdapat {} film dengan {} fitur yang terdapat pada dataset.".format(df_mov.shape[0],df_mov.shape[1]))

# menampilkan informasi singkat tentang dataset
df_mov.info()

# menampilkan deskripsi dari fitur data numerik
df_mov.describe()

"""# Text Preprocessing

Pada tahap ini, akan dilakukan pemrosesan text terhadap fitur Overview pada dataset. Fitur Overview akan dijadikan bahan untuk menghitung similarity antar data/film.
"""

# mengambil kolom/fitur Overview dari data frame
overview_words = df_mov['Overview']

# menampilkan hasil dari kolom yang diambil
overview_words

# sampel dari overview pada suatu kolom
overview_words[0]

"""## Remove Punctuation

Remove Punctuation merupakan bagian dimana semua tanda baca sepert titik, koma, atau tanda tanya akan dihapus atau dihilangkan.
"""

# menyalin overview dari data
filter_punc = overview_words.copy()

# proses penghilangan tanda baca
for i in range(len(overview_words)):
    filter_punc[i] =  "".join(u for u in overview_words[i] if u not in ("?", ".", ";", ":", "!", ",", "'"))

# sampel hasil dari penghilangan tanda baca
filter_punc[0]

"""## Lowercase Sentence

Lowercase Sentence merupakan bagian dimana semua kata dalam Overview akan dijadikan lowercase atau berawalan huruf kecil.
"""

# membagi deskripsi pada overview ke dalam bentuk per kata
for i in range(len(filter_punc)):
    filter_punc[i] = filter_punc[i].split(" ")

filter_punc

# menyalin hasil dari penghilangan tanda baca
filter_low = filter_punc.copy()

# proses perubahan kata menjadi lowercase
for i in range(len(filter_punc)):
    for j in range(len(filter_punc[i])):
        filter_low[i][j] = filter_punc[i][j].lower()

# sampel hasil dari lowercase setiap kata
filter_low[0]

"""## Eliminate Stopwords

Eliminate Stopwords merupakan bagian dimana kata-kata umum, dalam kasus ini dalam bahasa Inggris, seperti I, you, atau and akan dihilangkan.
"""

# me-set stopwords dalam bahasa inggris
set(stopwords.words('english'))

# menyalin hasil dari lowercase kata
filter_stop = filter_low.copy()

# proses eliminasi stopwords
for i in range(len(filter_low)):
    filter_stop[i] = " ".join(u for u in filter_low[i] if u not in set(stopwords.words('english')))

# sampel hasil dari eliminasi stopwords bahasa inggris
filter_stop[0]

"""## Stemming

Stemming merupakan bagian dimana semua bentuk kata dalam bahasa inggris akan dikembalikan atau disamakan dengan kata dasarnya.
"""

# membagi deskripsi pada overview ke dalam bentuk per kata
for i in range(len(filter_stop)):
    filter_stop[i] = filter_stop[i].split(" ")

filter_stop

# menyalin hasil eliminasi stopwords
filter_stem = filter_stop.copy()

for i in range(len(filter_stop)):
    for j in range(len(filter_stop[i])):
        filter_stem[i][j] = stemmer.stem(filter_stop[i][j])

# sampel hasil dari stemming
filter_stem[0]

"""# Word Dict and Total Words

Pada tahap ini, akan dilihat kembali informasi seputar overview dari dataset setelah dilakukan text prepropcessing. Tahap ini menampilkan jumlah kata pada keseluruhan overview dan kata yang paling sering muncul.
"""

# list untuk mengambil semua kata hasil preprocessing
total_words = []

# memasukkan semua kata ke dalam list
for i in range(len(filter_stem)):
    for j in range(len(filter_stem[i])):
        total_words.append(filter_stem[i][j])

# menghitung panjang list
print("Total keseluruhan kata dalam Overview setelah dilakukan Text Preprocessing adalah {} kata".format(len(total_words)))

# menghitung jumlah untuk masing-masing kata yang unik ke dalam kamus
word_dict = {i:total_words.count(i) for i in total_words}

print(word_dict)

# menampilkan jumlah kata unik dalam data
print("Dari total keseluruhan kata sebelumnya, terdapat {} kata unik.".format(len(word_dict)))

# mengurutkan kamus data kata-kata unik
sort_orders = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)

# menampilkan jumlah kata-kata unik secara terurut
print(sort_orders)

"""# Merge Data Set

Pada tahap ini, akan digabungkan kembali hasil dari overview yang sudah dilakukan text preprocessing ke dalam data frame.
"""

# menyalin hasil setelah stemming
overview_preprocessed = filter_stem.copy()

# menggabungkan kembali kata-kata yang terpisah menjadi satu kalimat.
for i in range(len(filter_stem)):
    overview_preprocessed[i] =  " ".join(u for u in filter_stem[i])

# menampilkan hasil overview yang sudah dilakukan text preprocessing
overview_preprocessed

# menyalin data frame movie
df_copy = df_mov.copy()

# menambahkan kolom baru berisikan overview yang baru
df_copy['Overview_Preprocessed'] = overview_preprocessed

# menampilkan sampel data pertama
df_copy.head(1)

"""# TF-IDF and Cosine Similarity

Pada tahap ini, akan dibangun TF-IDF dan cosine similarity menggunakan library yang sudah di-import sebelumnya.
"""

# me-set index dari data frame dengan nama/judul film
df_copy.set_index('Series_Title', inplace=True)

# inisiasi libray TF-IDF
tf = TfidfVectorizer(analyzer='word')

# hasil TF-IDF untuk kolom overview_preprocessed pada data
tfidf_matrix = tf.fit_transform(df_copy['Overview_Preprocessed'])

# menghitung cosine similarity dari matriks TF-IDF yang dihasilkan
cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# menampilkan hasil dari cosine similarity
cos_sim

"""# Modelling Recommender System

Pada tahap ini, akan dilakukan pemodelan sistem pemberi rekomendasi dalam bentuk fungsi. Fungsi ini akan melihat film yang memiliki tingkat similarity paling besar dari judul yang diberikan.
"""

# menyimpan indeks dari data frame ke dalam bentuk series
indices = pd.Series(df_copy.index)

# menampilkan data dari 50 data pertama
indices[:50]

def recommendations(name, cos_sim = cos_sim):
    
    # list untuk menampung film yang direkomendasi
    recommended_movie = []
    
    # mengambil judul film berdasarkan variabel indicies
    idx = indices[indices == name].index[0]

    # membuat series berdasarkan tingkat similarity
    score_series = pd.Series(cos_sim[idx]).sort_values(ascending = False)

    # mengambil index dan dibuat 10 baris rekomendasi terbaik
    top_10_indexes = list(score_series.iloc[1:11].index)
    
    # memasukkan 10 film rekomendasi terbaik ke dalam list
    for i in top_10_indexes:
        recommended_movie.append(list(df_copy.index)[i])

    # mengambil nilai similarity untuk film yang direkomendasi
    score_movies = score_series.iloc[1:11].values.tolist()

    # mengambil link poster film untuk keperluan GUI
    poster_movies = df_copy.iloc[top_10_indexes]['Poster_Link'].values.tolist()
        
    return recommended_movie, score_movies, poster_movies

# contoh rekomendasi untuk film 'Batman Begins'
recommendations('Batman Begins')

